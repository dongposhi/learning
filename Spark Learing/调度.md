
## spark 提交任务的处理流程


![enter image description here](https://img-blog.csdnimg.cn/20190107145653228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMTc0Mjg1,size_16,color_FFFFFF,t_70)

1. Spark cluster 由 一个Master 和 N个Worker 节点构成。以Standalone为例，这个cluster 是在conf 里面定义好的。一旦launch （start-all）这个cluster service 就开始提供服务。
2. spark-submit 只是一个cmd 部署工具，不属于spark cluster 的核心组件
3. Master 节点提供RPC endpoint 对外接受 application 申请
4. 每个Application被接受后会分配Driver和executor 来执行。
	1. **Master**, **Worker** 是部署范畴的概念
	2. **Master**，**Driver**, **Executor** 是应用执行层面上的概念
		1. **Master** 在这里也是执行层面的资源调度者
		2. 这三者都是以进程的形态存在
		3. **Master** 掌控着**Driver**和**Executor** 的创建（standalone 模式下 ssh 远程启动？） 
		4. **Master** 和**Driver** 都是调度者，只是调度对象不同。**Master**是计算资源调度；而**Driver** 是Stage，Task 调度。
5. Driver 和Executor 都是是运行在某一个Worker上的。一个应用只有一个Driver，但是可以有多个Executor。每个Worker 上可以既有Driver 在运行，也可以有多个Executor 在运行。
![enter image description here](https://img-blog.csdn.net/20181011152626889?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTg4NDkz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


### [核心概念](https://www.cnblogs.com/superhedantou/p/5699201.html)
Application, Driver, Job, Stage, Task,

- **JOB**: 每个Action 算子对应一个JOB 
- **SparkContext** 对象是在**Driver** 上实例化，也就是说我们写的程序（application）是运行在Driver 上。
- **Stage 的并行度是由最后一个 RDD 的分区决定的**
在互联网的概念中，并行度是指可同时开辟的线程数 ，并发数是指每个线程中可处理的最大数据量，比如： 4 个线程，每个线程可处理的数据为 100 万条，那么并行度就是 4，并发量是 100 万；而对于 stage 而言，即使其中的 task是分批进行执行的，也都算在并行度中，比如，stage 中有 100 个 task，而这 100 个 task 分4 批次才能执行完，那么该 stage 的并行度也为 100。
#### OPEN ISSUES
1. 每个cluster 上可以接受多个Application，他们的运行策略是什么？是串行FIFO，还是并行（最大化利用资源）？
2. 运行在Executor上的Task 是以什么方式存在的？

## 任务调度

Acition ->Job (sc.runJob)---> DAGScheduler.runJob--->TaskScheduler.submitTasks

### TaskScheduler

TaskScheduler.launchTask() 发送Task （序列化）到指定的Executor（反序列化） 中去执行（TaskRunner）。

**Task** 是一个执行单元。一共有两种Task
1. **ShuffleMapTask**   map?
 *ShuffleMapTask* 是一个管道，管道结果会在shuffle write 阶段数据落地。
 执行完成后会向**Driver**发送执行状态 
2. **ResultTask**             reduce?
 ResultTask 所依赖的上一stage 的Map 结果需要从其执行者（Executor）拉去。这两个Executor 之间通过Driver 来交换必要的信息后建立连接（类似于SSH 的握手）从而交换数据。
<!--stackedit_data:
eyJoaXN0b3J5IjpbODUzODgzNjk1LC0xODEzOTI5NTEzLC01Mz
kzNjcyOTUsMTgxMTIyNDE0LDEwMTUzOTI5NzcsLTk1MzAzNTQ4
MCwxMDUxNzg5OTgxLDE2Njk3MTUxOTNdfQ==
-->